---
date: 'Report generated `r format(Sys.time(), "%A, %B %d, %Y")`'
output:
 html_document:
  toc: TRUE
  toc_float: TRUE
params:
   country: "Brazil"
   pre_period_start: '2004-01-01'
   pre_period_end: '2009-12-31'
   post_period_start: '2010-01-01'
   post_period_end: '2013-12-01'
   eval_period_start: '2012-01-01' 
   eval_period_end: '2013-12-01'
   year_def: 'cal_year'
   sensitivity: FALSE
   crossval: FALSE
   group_name: 'age_group'
   date_name: 'date'
   outcome_name: 'J12_18'  
   denom_name: 'ach_noj' 
   n_seasons: 12
   input_directory: 'https://raw.githubusercontent.com/weinbergerlab/synthetic-control/master/Datasets%20for%20PNAS/'
   file_name: "Dataset%20S1%20Brazil.csv"
   github.import: TRUE 
   update_packages: FALSE 
   install_packages: TRUE 
---

---
title: "Estimated change associated with the introduction of vaccine in `r params$country`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,message = FALSE, warnings = FALSE)
source("synthetic_control_functions.R")
source("../R/analysis.R")
```

```{r specify_inputs, include=FALSE}
  update_packages  <- params$update_packages 
  install_packages <- params$install_packages 
  install_pandoc   <- FALSE
```

```{r load_packages, include = FALSE}

packages <- c('knitr','parallel','RCurl' ,'pomp','splines', 'MASS', 'lubridate','loo', 'RcppRoll','lme4', 'ggplot2', 'reshape','dummies')
packageHandler(packages, update_packages, install_packages)
sapply(packages, library, quietly = TRUE, character.only = TRUE)

#Detect if pogit package installed; if not download from Github
if("pogit" %in% rownames(installed.packages())==FALSE){
  if("devtools" %in% rownames(installed.packages())==FALSE){
    install.packages('devtools')
  }
  library('devtools')
  install_github("airbornemint/pogit") #Did not update any of the dependencies (#24)
}
library(pogit)
library(gsubfn)
```

```{r setup_data, include=FALSE}
output_directory <- 'Results' #Directory where results will be saved.
output_directory <- paste(output_directory,'_',params$country,'_', format(Sys.time(), '%Y-%m-%d-%H%M%S'), '/', sep = '') #Adds a subfolder to output directory to organize results by date and time run.
dir.create(output_directory, recursive = TRUE, showWarnings = FALSE)

syncon = with(params, {
  syncon_factory$new(
    country, input_directory, file_name, github.import, 
    pre_period_start, pre_period_end, 
    post_period_start, post_period_end, 
    eval_period_start, eval_period_end, 
    n_seasons, year_def, 
    group_name, date_name, outcome_name, denom_name
  )
})
set.seed(1)
```

```{r main analysis, include = FALSE}
impact_results = syncon$impact()
```

```{r crossval, include = FALSE}
  if(params$crossval){
    syncon$crossval()

    save.stack.est<-list(post_period,syncon$outcome, time_points,syncon$ann_pred_quantiles_stack, syncon$pred_quantiles_stack,syncon$rr_roll_stack,syncon$rr_mean_stack,syncon$rr_mean_stack_intervals,syncon$cumsum_prevented_stack)
    names(save.stack.est)<-c('post_period','outcome','time_points', 'ann_pred_quantiles_stack', 'pred_quantiles_stack','rr_roll_stack','rr_mean_stack','rr_mean_stack_intervals','cumsum_prevented_stack')
    saveRDS(save.stack.est, file=paste0(output_directory, params$country, "Stack estimates.rds"))
    
    #Pointwise RR and uncertainty for second stage meta analysis
    log_rr_quantiles_stack   <- sapply(syncon$quantiles_stack,   FUN = function(quantiles) {quantiles$log_rr_full_t_quantiles}, simplify = 'array')
    dimnames(log_rr_quantiles_stack)[[1]] <- time_points
    log_rr_full_t_samples.stack.prec<-sapply(syncon$quantiles_stack,   FUN = function(quantiles) {quantiles$log_rr_full_t_samples.prec.post}, simplify = 'array')
    #log_rr_sd.stack   <- sapply(syncon$quantiles_stack,   FUN = function(quantiles) {quantiles$log_rr_full_t_sd}, simplify = 'array')
    
    saveRDS(log_rr_quantiles_stack, file=paste0(output_directory, params$country, "_log_rr_quantiles_stack.rds"))
    saveRDS(log_rr_full_t_samples.stack.prec, file=paste0(output_directory, params$country, "_log_rr_full_t_samples.stack.prec.rds"))
  }
```

```{r format_save_results, include = FALSE}

for (analysis in c('full', 'best')) {
  saveRDS(impact_results[[analysis]]$log_rr_quantiles, file=paste0(output_directory, params$country, "_", analysis, "_log_rr_quantiles.rds"))
  saveRDS(impact_results[[analysis]]$log_rr_sd, file=paste0(output_directory, params$country, "_", analysis, "_log_rr_sd.rds"))
  saveRDS(impact_results[[analysis]]$log_rr_t_samples.prec, file=paste0(output_directory, params$country, "_", analysis, "_log_rr_t_samples.prec.rds"))
}

#Save output of ITS analysis (rr at last time point) as .csv
write.csv(impact_results$its$rr_end, paste(output_directory, params$country, 'rr_classic_its.csv', sep = ''))

#Combine RRs into 1 file for plotting
rr_mean_combo<- as.data.frame(rbind(
  cbind(rep(1, nrow(impact_results$full$rr_mean)), syncon$groups, seq(from=1, by=1, length.out=nrow(impact_results$full$rr_mean)), impact_results$full$rr_mean),
  cbind(rep(2, nrow(impact_results$time$rr_mean)), syncon$groups, seq(from=1, by=1, length.out=nrow(impact_results$time$rr_mean)), impact_results$time$rr_mean),
  cbind(rep(3, nrow(impact_results$time_no_offset$rr_mean)), syncon$groups, seq(from=1, by=1, length.out=nrow(impact_results$time_no_offset$rr_mean)), impact_results$time_no_offset$rr_mean),
  cbind(rep(4, nrow(impact_results$pca$rr_mean)), syncon$groups, seq(from=1, by=1, length.out=nrow(impact_results$pca$rr_mean)), impact_results$pca$rr_mean)
))

names(rr_mean_combo)<-c('Model', 'groups', 'group.index', 'lcl', 'mean.rr', 'ucl')
if(params$crossval){
  point.weights2<-syncon$stacking_weights.all.m
}else{
  point.weights2<-as.data.frame(matrix(rep(1,nrow(rr_mean_combo)), ncol=1))
  names(point.weights2)<-'value'
}
rr_mean_combo$point.weights <- point.weights2$value
rr_mean_combo$group.index <- as.numeric(as.character(rr_mean_combo$group.index))
rr_mean_combo$mean.rr <- as.numeric(as.character(rr_mean_combo$mean.rr))
rr_mean_combo$lcl <- as.numeric(as.character(rr_mean_combo$lcl))
rr_mean_combo$ucl <- as.numeric(as.character(rr_mean_combo$ucl))
rr_mean_combo$group.index[rr_mean_combo$Model==2] <- rr_mean_combo$group.index[rr_mean_combo$Model==2]+0.15
rr_mean_combo$group.index[rr_mean_combo$Model==3] <- rr_mean_combo$group.index[rr_mean_combo$Model==3]+0.3
rr_mean_combo$group.index[rr_mean_combo$Model==4] <- rr_mean_combo$group.index[rr_mean_combo$Model==4]+0.45
rr_mean_combo$Model <- as.character(rr_mean_combo$Model)
rr_mean_combo$Model[rr_mean_combo$Model=='1'] <- "Synthetic Controls"
rr_mean_combo$Model[rr_mean_combo$Model=='2'] <- "Time trend"
rr_mean_combo$Model[rr_mean_combo$Model=='3'] <- "Time trend (No offset)"
rr_mean_combo$Model[rr_mean_combo$Model=='4'] <- "STL+PCA"
cbPalette  <-  c("#1b9e77", "#d95f02", "#7570b3",'#e7298a')
rr_mean_combo$est.index <- as.factor(1:nrow(rr_mean_combo))
#Fix order for axis
rr_mean_combo$Model <- as.factor(rr_mean_combo$Model)
rr_mean_combo$Model <- factor(rr_mean_combo$Model,levels(rr_mean_combo$Model)[c(2,3,4,1)])
#print(levels(rr_mean_combo$Model))

# TODO
# save.best.est<-list(impact_results$best$log_rr_sd,post_period,syncon$outcome, syncon$time_points,impact_results$best$ann_pred_quantiles, impact_results$best$pred_quantiles,impact_results$best$rr_roll,impact_results$best$rr_mean,impact_results$best$rr_mean_intervals,impact_results$best$cumsum_prevented)
# names(save.best.est)<-c('log_rr_sd_best','post_period','outcome','time_points', 'ann_pred_quantiles_best', 'pred_quantiles_best','rr_roll_best','rr_mean_best','rr_mean_best_intervals','cumsum_prevented_best')
# saveRDS(save.best.est, file=paste0(output_directory, country, "best estimates.rds"))

```

```{r sensitivity_analyses, include = FALSE}
if(params$sensitivity){
  syncon$sensitivity()
}

```


#`r params$country` Results

```{r sparse}
if (!is.null(names(syncon$sparse_groups[syncon$sparse_groups])) && length(names(syncon$sparse_groups[syncon$sparse_groups])) != 0) {
	kable(data.frame('Sparse Groups' = names(syncon$sparse_groups[syncon$sparse_groups]), check.names = FALSE), align = 'c')
}
```

##combine estimates
```{r Comparison of estimates from different models}
if (params$crossval){
kable( cbind.data.frame(rr_mean_stack_intervals,rr_mean_full_intervals,rr_mean_time_intervals,rr_mean_time_no_offset_intervals,rr_mean_its_intervals, rr_mean_pca_intervals), align = 'c')
}else{
kable( cbind.data.frame(impact_results$best$rr_mean_intervals,impact_results$full$rr_mean_intervals,impact_results$time$rr_mean_intervals,impact_results$time_no_offset$rr_mean_intervals,impact_results$its$rr_mean_intervals, impact_results$pca$rr_mean_intervals), align = 'c')  
}
```

##Plot of Rate ratios, with size proportional to cross validation weights
```{r fig.width=5, fig.height=3, fig.align = "center", dpi=300, echo=FALSE}
#Compare rate ratios, with size of marker scaled to cross val weights
		ggplot(rr_mean_combo, aes(x=group.index, y=mean.rr, color=Model,group=Model)) + 
	  geom_errorbar(aes(ymin=lcl, ymax=ucl), colour="gray", width=.0) +
	  geom_point(aes(shape=Model, size=est.index))+
     scale_shape_manual(values=c(15, 16, 17,18))+
	  scale_size_manual(values=c(point.weights2$value*2)) + #Scales area, which is optimal for bubbl plot
	  #geom_errorbar(rr_mean_combo,aes(ymin=lcl, ymax=ucl), colour="black", width=.1) +
	  theme_bw() +
	  guides(size=FALSE)+ #turn off size axis
	  scale_colour_manual(values=cbPalette)+
	  labs(x = "Group", y="Rate ratio")+
	  geom_hline(yintercept = 1, colour='gray',linetype = 2)+
	  theme(axis.line = element_line(colour = "black"),
	        legend.position=c(0.2, 0.9),
	        panel.grid.major = element_blank(),
	        panel.grid.minor = element_blank(),
	        panel.border = element_blank(),
	        panel.background = element_blank()) 
```

##Weights for each of the models from cross validation
```{r Comparison of Cross validation Weights from different models}
if(params$crossval){
kable(stacking_weights.all, align = 'c')
} else{
      print("Cross-validation not performed")
    }
```
  
##Number of variables selected in SC analysis
```{r modelsize}
kable(syncon$model_size, col.names=c('Model Size'))
```

##Inclusion Probabilities
```{r incl, include = FALSE}
incl_probs <- NULL
	for (group in syncon$groups) {
	    incl_prob=impact_results$full$groups[[group]]$inclusion_probs[-c(1:(syncon$n_seasons-1)),]
	    incl_prob<- incl_prob[order(-incl_prob$inclusion_probs),]
	    incl_prob<-incl_prob[c(1:3),]
	    incl_prob2<-incl_prob[,2]
	    incl_prob_names=incl_prob[,1]
			incl_prob3 <- data.frame('Group' = group, 'Greatest Inclusion Variable' = incl_prob_names[1], 'Greatest Inclusion Probability' = incl_prob2[1], 'Second Greatest Inclusion Variable' = incl_prob_names[2], 'Second Greatest Inclusion Probability' = incl_prob2[2], 'Third Greatest Inclusion Variable' = incl_prob_names[3], 'Third Greatest Inclusion Probability' = incl_prob2[3], check.names = FALSE)
			incl_probs <- rbind(incl_probs, incl_prob3)
		}
rownames(incl_probs) <- NULL
```

```{r incl_table}
kable(incl_probs, align = 'c')
```

##Weight Sensitivity Analysis
```{r sensitivity}
if (exists('sensitivity_table_intervals')) {
kable(sensitivity_table_intervals, align = 'c')
}
```


##Plots
```{r plots,fig.height =3 , fig.width = 5, fig.align = "center", dpi=300,results = 'asis'}
source('./synthetic_control_plot.R', local=FALSE)
```

##Print results
```{r save_results, echo=FALSE}
source('./synthetic_control_write_results.R', local = FALSE)

```